{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1j8duJElVw-r6MTV701dPjt7afVrYxsPp",
      "authorship_tag": "ABX9TyM1pQ9B3VHLXtQ/TXrJrxV2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ellyasiml/CNN-LSTM-sentiment-analysis/blob/main/ta_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install symspellpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pt6uQ0TpA_g",
        "outputId": "d21fce25-f456-4ada-a57b-83e93b0fa4c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: symspellpy in /usr/local/lib/python3.9/dist-packages (6.7.7)\n",
            "Requirement already satisfied: editdistpy>=0.1.3 in /usr/local/lib/python3.9/dist-packages (from symspellpy) (0.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g87FtrLNk7L9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from symspellpy import SymSpell, Verbosity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load GloVe embedding\n",
        "embedding_dim = 100\n",
        "embedding_dict = {}\n",
        "with open(\"drive/MyDrive/dataset/dataset TA/glove.twitter.27B.100d.txt\", 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_dict[word] = vector"
      ],
      "metadata": {
        "id": "Ikx8Slybmu2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained CNN model\n",
        "cnn_model = tf.keras.models.load_model('drive/MyDrive/dataset/dataset TA/cnn_model.h5')\n",
        "\n",
        "# Load the pre-trained LSTM model\n",
        "lstm_model = tf.keras.models.load_model('drive/MyDrive/dataset/dataset TA/lstm_model.h5')\n",
        "\n",
        "# Load the dataset of tweets you want to predict sentiment for\n",
        "tweets_df = pd.read_csv('drive/MyDrive/dataset/dataset TA/data_combined.csv')\n",
        "tweets = tweets_df[\"tweet\"].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-XxX-BOk_p7",
        "outputId": "e816c03e-0e07-4add-a65b-6924f1d16e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-d7b050750f81>:8: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  tweets_df = pd.read_csv('drive/MyDrive/dataset/dataset TA/data_combined.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create SymSpell instance\n",
        "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
        "dictionary_path = \"drive/My Drive/dataset/dataset TA/wiki-id-formatted-1000.txt\"\n",
        "term_index = 0\n",
        "count_index = 1\n",
        "if not sym_spell.load_dictionary(dictionary_path, term_index, count_index):\n",
        "    print(\"Dictionary file not found\")\n",
        "\n",
        "# function to correct spelling errors in tweets\n",
        "def correct_spellings(text):\n",
        "    suggestions = sym_spell.lookup_compound(text, max_edit_distance=2)\n",
        "    corrected_text = suggestions[0].term if suggestions else text\n",
        "    return corrected_text\n",
        "\n",
        "# correct spelling errors in tweets\n",
        "tweets = [correct_spellings(tweet) for tweet in tweets]"
      ],
      "metadata": {
        "id": "HF6F41sIm63w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the tweets to sequences of integers using the same tokenizer that was used to train the model\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(tweets_df['tweet'])\n",
        "sequences = tokenizer.texts_to_sequences(tweets_df['tweet'])"
      ],
      "metadata": {
        "id": "brnOxoUKlBt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to compute the maximum input shape across multiple models\n",
        "def get_max_input_shape(models):\n",
        "    max_length = 0\n",
        "    for model in models:\n",
        "        if model.input_shape[1] > max_length:\n",
        "            max_length = model.input_shape[1]\n",
        "    return max_length\n",
        "  \n",
        "# Pad the sequences to the maximum input shape across both models\n",
        "max_length = get_max_input_shape([cnn_model, lstm_model])\n",
        "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_length)"
      ],
      "metadata": {
        "id": "6-ZuAquWqEYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create embedding matrix\n",
        "num_words = min(5000, len(tokenizer.word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i >= 5000:\n",
        "        continue\n",
        "    embedding_vector = embedding_dict.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "UR_jcqDhnNjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the CNN model to predict the sentiment of the tweets\n",
        "cnn_predictions = cnn_model.predict(padded_sequences)\n",
        "\n",
        "# Use the LSTM model to predict the sentiment of the tweets\n",
        "lstm_predictions = lstm_model.predict(padded_sequences)\n",
        "\n",
        "# Round the predictions to either 0 or 1\n",
        "cnn_labels = np.round(cnn_predictions).astype(int)\n",
        "lstm_labels = np.round(lstm_predictions).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZE9HTiclFEG",
        "outputId": "97160e7f-d2b9-476f-f6df-52dcdc565344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2104/2104 [==============================] - 25s 12ms/step\n",
            "2104/2104 [==============================] - 45s 21ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg1yNAinyBwZ",
        "outputId": "ead951c8-0e90-45b2-b82a-044754e64597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       ...,\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKps2c9kz-h8",
        "outputId": "d585fc59-7989-4cec-ec3c-85bf1f63ccec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       ...,\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the predictions to 1D arrays\n",
        "cnn_labels = np.array([1 if pred[0] < 0.5 else 0 for pred in cnn_predictions])\n",
        "lstm_labels = np.array([1 if pred[0] < 0.5 else 0 for pred in lstm_predictions])"
      ],
      "metadata": {
        "id": "hrAU0P9u0AMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-Al_uWa0CwS",
        "outputId": "9d0175d6-b323-40e6-cb1e-e5df42dca25e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7op9kqf0DTz",
        "outputId": "c6f8a51c-ddfe-466e-bedb-8c0597fee3b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the predictions to the tweets_df dataframe\n",
        "tweets_df[\"cnn_prediction\"] = cnn_labels\n",
        "tweets_df[\"lstm_prediction\"] = lstm_labels"
      ],
      "metadata": {
        "id": "W6YoLRMg0fSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the predictions to a single CSV file\n",
        "combined_df = tweets_df[[\"tweet\", \"cnn_prediction\", \"lstm_prediction\"]]\n",
        "combined_df.to_csv(\"combined_predictions.csv\", index=False)"
      ],
      "metadata": {
        "id": "0r9V2CXl0n2_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}